{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils\n!pip install keras-segmentation\nimport imutils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import SGD, Adam, RMSprop\nfrom keras.layers import (\n    Conv2D, BatchNormalization, MaxPooling2D, Dropout, Activation, UpSampling2D, concatenate, Reshape, ZeroPadding2D\n)\nimport cv2\nimport imutils\nfrom sklearn.utils import shuffle\nimport keras.backend as K\nfrom keras.models import Sequential, Model, Input\nfrom keras.regularizers import l2\nimport numpy as np\nfrom keras.callbacks import ModelCheckpoint\nimport imgaug as ia\nfrom imgaug import augmenters as iaa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Constant variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_TRAIN_DIR = \"../input/segmentsampledataset/dataset1/dataset1/images_prepped_train/\"\nANNO_TRAIN_DIR = \"../input/segmentsampledataset/dataset1/dataset1/annotations_prepped_train/\"\nIMG_VAL_DIR = \"../input/segmentsampledataset/dataset1/dataset1/images_prepped_test/\"\nANNO_VAL_DIR = \"../input/segmentsampledataset/dataset1/dataset1/annotations_prepped_test/\"\nBATCH_SIZE = 16\nHEIGHT = 224\nWIDTH = 224\nCHANNEL = 3\nIMAGE_AUGMENTATION_SEQUENCE= None\nIMAGE_AUGMENTATION_NUM_TRIES = 10\nIMAGE_AUMENTATION_NAME_LOADED = \"\"\nN_CLASSES=12","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _load_augmenation_aug_geometric():\n    return iaa.OneOf([\n        iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.2)]),\n        iaa.CropAndPad(percent=(-0.05, 0.1),\n                       pad_mode=\"constant\",\n                       pad_cval=(0, 255)),\n        iaa.Crop(percent=(0.0, 0.1)),\n        iaa.Crop(percent=(0.3, 0.5)),\n        iaa.Crop(percent=(0.3, 0.5)),\n        iaa.Crop(percent=(0.3, 0.5)),\n        iaa.Sequential([\n            iaa.Affine(\n                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n                translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n                rotate=(-45, 45),\n                shear=(-16, 16),\n                # Use nearest neighborhood or bilinear interpolation\n                order=[0,1],\n                mode=\"constant\",\n                cval=(0, 255),\n            ),\n            iaa.Sometimes(0.3, iaa.Crop(percent=(0.3, 0.5)))\n        ])\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _load_augmentation_agu_non_geometric():\n    return iaa.Sequential([\n        iaa.Sometimes(0.3, iaa.Multiply((0.5, 1.5), per_channel=0.5)),\n        iaa.Sometimes(0.2, iaa.JpegCompression(compression=(70, 99))),\n        iaa.Sometimes(0.2, iaa.GaussianBlur(sigma=(0, 3.0))),\n        iaa.Sometimes(0.2, iaa.MotionBlur(k=15, angle=[-45, 45])),\n        iaa.Sometimes(0.2, iaa.MultiplyHue((0.5, 1.5))),\n        iaa.Sometimes(0.2, iaa.MultiplySaturation((0.5, 1.5))),\n        iaa.Sometimes(0.34, iaa.MultiplyHueAndSaturation((0.5, 1.5), per_channel=True)),\n        iaa.Sometimes(0.34, iaa.Grayscale(alpha=(0.0, 1.0))),\n        iaa.Sometimes(0.2, iaa.ChangeColorTemperature((1100, 10000))),\n        iaa.Sometimes(0.1, iaa.GammaContrast((0.5, 2.0))),\n        iaa.Sometimes(0.2, iaa.SigmoidContrast(gain=(3, 10),\n                                               cutoff=(0.4, 0.6))),\n        iaa.Sometimes(0.1, iaa.CLAHE()),\n        iaa.Sometimes(0.1, iaa.HistogramEqualization()),\n        iaa.Sometimes(0.2, iaa.LinearContrast((0.5, 2.0), per_channel=0.5)),\n        iaa.Sometimes(0.1, iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)))\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _load_augmentation_aug_all2():\n    return iaa.Sequential([\n        iaa.Sometimes(0.65, _load_augmenation_aug_geometric()),\n        iaa.Sometimes(0.65, _load_augmentation_agu_non_geometric()),\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _load_augmentation_aug_all():\n    def sometimes(aug):\n        return iaa.Sometimes(0.5, aug)\n    \n    return iaa.Sequential([\n        iaa.Fliplr(0.5),\n        iaa.Flipud(0.2),\n        sometimes(iaa.CropAndPad(\n            percent=(-0.05, 0.1),\n            pad_mode=\"constant\",\n            pad_cval=(0, 255)\n        )),\n        sometimes(iaa.Affine(\n            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n            rotate=(-45, 45),\n            shear=(-16, 16),\n            # Use nearest neighborhood or bilinear interpolation\n            order=[0,1],\n            mode=\"constant\",\n            cval=(0, 255),\n        )),\n        iaa.SomeOf((0,5), \n                   [\n            # convert images into their superpixel representation\n            sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))),\n            iaa.OneOf([\n                # blur images with a sigma between 0 and 3.0\n                iaa.GaussianBlur((0, 3.0)),\n                # blur image using local means with kernel sizes\n                # between 2 and 7\n                iaa.AverageBlur(k=(2, 7)),\n                # blur image using local medians with kernel sizes\n                # between 2 and 7\n                iaa.MedianBlur(k=(3, 11)),\n            ]),\n            iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),  # sharpen images\n            iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),  # emboss images\n            iaa.SimplexNoiseAlpha(iaa.OneOf([\n                iaa.EdgeDetect(alpha=(0.5, 1.0)),\n                iaa.DirectedEdgeDetect(\n                    alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n            ])),\n            # add gaussian noise to images\n            iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n            iaa.OneOf([\n                # randomly remove up to 10% of the pixels\n                iaa.Dropout((0.01, 0.1), per_channel=0.5),\n                iaa.CoarseDropout((0.03, 0.15), size_percent=(\n                    0.02, 0.05), per_channel=0.2),\n            ]),\n            # invert color channels\n            iaa.Invert(0.05, per_channel=True),\n            # change brightness of images (by -10 to 10 of original value)\n            iaa.Add((-10, 10), per_channel=0.5),\n            # change hue and saturation\n            iaa.AddToHueAndSaturation((-20, 20)),\n            # either change the brightness of the whole image (sometimes\n            # per channel) or change the brightness of subareas\n            iaa.OneOf([\n                iaa.Multiply((0.5, 1.5), per_channel=0.5),\n                iaa.FrequencyNoiseAlpha(\n                    exponent=(-4, 0),\n                    first=iaa.Multiply((0.5, 1.5), per_channel=True),\n                    second=iaa.ContrastNormalization((0.5, 2.0))\n                )\n            ]),\n            # improve or worsen the contrast\n            iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),\n            iaa.Grayscale(alpha=(0.0, 1.0)),\n            # move pixels locally around (with random strengths)\n            sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)),\n            # sometimes move parts of the image around\n            sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n            sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n        ], \n            random_order=True\n        )\n    ], random_order=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_augm_support = {\n    \"aug_all\": _load_augmentation_aug_all,\n    \"aug_all2\": _load_augmentation_aug_all2,\n    \"aug_geometric\": _load_augmenation_aug_geometric,\n    \"aug_non_geometric\": _load_augmentation_agu_non_geometric\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_aug(aug_name=\"aug_all\"):\n    global IMAGE_AUGMENTATION_SEQUENCE\n    \n    if not aug_name in list_augm_support.keys():\n        raise ValueError(\"Aug function does not support\")\n    \n    IMAGE_AUGMENTATION_SEQUENCE = list_augm_support[aug_name]()\n    \n    return IMAGE_AUGMENTATION_SEQUENCE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def aug_image(image, seg, aug_name=\"aug_all\"):\n    global IMAGE_AUMENTATION_NAME_LOADED\n    \n    if not IMAGE_AUMENTATION_NAME_LOADED or IMAGE_AUGMENTATION_SEQUENCE is None:\n        load_aug(aug_name)\n        IMAGE_AUMENTATION_NAME_LOADED = aug_name\n    \n    # Create a deterministic from the random one\n    aug_det = IMAGE_AUGMENTATION_SEQUENCE.to_deterministic()\n    image_aug = aug_det.augment_image(image)\n    \n    segmap = ia.SegmentationMapOnImage(seg, nb_classes=np.max(seg) + 1, shape=image.shape)\n    segmap_aug = aug_det.augment_segmentation_maps(segmap)\n    segmap_aug = segmap_aug.get_arr_int()\n    \n    return image_aug, segmap_aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def try_n_times(fn, n, *args, **kwargs):\n    attemps = 0\n    \n    while attemps < n:\n        try:\n            return fn(*args, **kwargs)\n        except:\n            attemps += 1\n    \n    return fn(*args, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment_seg(img, seg, aug_name=\"aug_all\"):\n    return try_n_times(aug_image, IMAGE_AUGMENTATION_NUM_TRIES, img, seg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGeneration:\n    def __init__(self, img_train_dir, img_test_dir, anno_train_dir, anno_test_dir, batch_size,\n                 width, height, channel, nb_classes, apply_aug=True):\n        self.img_train_dir = img_train_dir\n        self.img_test_dir = img_test_dir\n        self.anno_train_dir = anno_train_dir\n        self.anno_test_dir = anno_test_dir\n        self.batch_size = batch_size\n        self.width = width\n        self.height = height\n        self.channel = channel\n        self.current_train = 0 \n        self.current_test = 0\n        self.image_train_paths = self.load_image_paths(self.img_train_dir)\n#         self.anno_train_paths = self.load_image_paths(self.anno_train_dir)\n        self.image_test_paths = self.load_image_paths(self.img_test_dir)\n#         self.anno_test_paths = self.load_image_paths(self.anno_test_dir)\n        self.nb_classes = nb_classes\n        self.apply_aug = apply_aug\n        \n    def load_image_paths(self, data_path):\n        image_paths = []\n        \n        for img in os.listdir(data_path):\n            img_path = os.path.join(data_path, img)\n            image_paths.append(img_path)\n        \n        image_paths = np.array(image_paths)\n        return image_paths\n    \n    def image_preprocess(self, img):\n        h, w = img.shape[:2]\n        d_w = 0\n        d_h = 0\n        \n        if h > w:\n            img = imutils.resize(img, width=self.width)\n            d_h = int((img.shape[0] - self.heigth)/2)\n        else:\n            img = imutils.resize(img, height=self.height)\n            d_w = int((img.shape[1] - self.width)/2)\n            \n        img = img[d_h:img.shape[1]-d_h, d_w: img.shape[0]-d_w]\n        img = cv2.resize(img, (self.height, self.width), interpolation=cv2.INTER_AREA)\n        return img\n    \n    def load_data(self, image_paths):\n        images = []\n        segs = []\n        \n        for i in range(0, len(image_paths)):\n            labels = np.zeros((self.height, self.width, self.nb_classes))\n            image = cv2.imread(image_paths[i])\n            image = image[:,:,::-1]\n            image = self.image_preprocess(image)    \n            \n            label_path = image_paths[i].replace('images', 'annotations')\n            label = cv2.imread(label_path, 0)\n            label = self.image_preprocess(label)\n            label = np.expand_dims(label, axis=-1)\n        \n            if self.apply_aug:\n                image, label = augment_seg(image, label)\n            \n            for c in range(self.nb_classes):\n                labels[:, :, c] = (label == c).astype(\"int\")\n    \n            image = image.astype('float')/255\n            images.append(image)\n            labels = np.reshape(labels, (self.width*self.height, self.nb_classes))\n#             labels = labels.astype('float')/255\n            segs.append(labels)\n            \n        segs = np.array(segs) \n        images = np.array(images)        \n\n        return images, segs\n\n    def next_train(self):\n        if self.current_train + self.batch_size > len(self.image_train_paths):\n            self.current_train = 0\n            self.image_train_paths = shuffle(self.image_train_paths, random_state=42)\n            \n        batch_X_paths = self.image_train_paths[self.current_train:self.current_train+self.batch_size]\n        batch_X, batch_y = self.load_data(batch_X_paths)\n        self.current_train += self.batch_size\n        \n        return batch_X, batch_y\n    \n    def next_test(self):\n        if self.current_test + self.batch_size > len(self.image_test_paths):\n            self.current_test = 0\n            self.image_test_paths = shuffle(self.image_test_paths, random_state=42)\n            \n        batch_X_paths = self.image_test_paths[self.current_test:self.current_test+self.batch_size]\n        batch_X, batch_y = self.load_data(batch_X_paths)\n        self.current_test += self.batch_size\n        \n        return batch_X, batch_y\n    \n    def get_batch(self, s=\"train\"):\n        while True:\n            if s == \"train\":\n                batch_X, batch_y = self.next_train()\n            else:\n                batch_X, batch_y = self.next_test()\n\n            yield (batch_X, batch_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gener = DataGeneration(IMG_TRAIN_DIR, IMG_VAL_DIR, ANNO_TRAIN_DIR, ANNO_VAL_DIR, BATCH_SIZE, WIDTH, HEIGHT, CHANNEL, N_CLASSES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_test_path = data_gener.image_test_paths[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_seg_test_path = data_gener.image_test_paths[0].replace('images', 'annotations')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_test = cv2.imread(img_test_path)\nimg_seg_test = cv2.imread(img_seg_test_path, 0)\nimg_seg_test = np.expand_dims(img_seg_test, axis=-1)\nimg_seg_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val, y_val = data_gener.load_data(data_gener.image_test_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data_gener.image_train_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_aug, img_seg_aug = augment_seg(img_test, img_seg_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# segmap = ia.SegmentationMapOnImage(img_seg_test, shape=img_test.shape, nb_classes=np.max(img_seg_test)+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img_aug)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img_seg_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"def initial_bias(shape, dtype=None):\n    return np.random.normal(loc=0.5, scale=1e-2, size=shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initial_weight(shape, dtype=None):\n    return np.random.normal(loc=0.0, scale=1e-2, size=shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def base_model(intput_height=HEIGHT, input_width=WIDTH, image_ordering=\"channels_last\"):\n    bn = -1\n    input_shape=(intput_height, input_width, 3)\n    pad = 1\n    pool_size = 2\n    filter_size = [64, 128, 256]\n    levels = []\n    \n    if image_ordering==\"channels_first\":\n        bn = 1\n        input_shape=(3, intput_height, input_width)\n    \n    img_input = Input(shape=input_shape)\n    x = ZeroPadding2D((pad, pad), data_format=image_ordering)(img_input)\n    x = Conv2D(filter_size[0], (3, 3), padding='valid', data_format=image_ordering)(x)\n    x = BatchNormalization(axis=bn)(x)\n    x = Activation(\"relu\")(x)\n    x = ZeroPadding2D((pad, pad), data_format=image_ordering)(x)\n    x = Conv2D(filter_size[0], (3, 3), padding='valid', data_format=image_ordering)(x)\n    x = BatchNormalization(axis=bn)(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPooling2D(pool_size=(pool_size, pool_size))(x)\n    levels.append(x)\n    \n    x = ZeroPadding2D((pad, pad), data_format=image_ordering)(x)\n    x = Conv2D(filter_size[1], (3, 3), padding='valid', data_format=image_ordering)(x)\n    x = BatchNormalization(axis=bn)(x)\n    x = Activation(\"relu\")(x)\n    x = ZeroPadding2D((pad, pad), data_format=image_ordering)(x)\n    x = Conv2D(filter_size[1], (3, 3), padding='valid', data_format=image_ordering)(x)\n    x = BatchNormalization(axis=bn)(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPooling2D(pool_size=(pool_size, pool_size))(x)\n    levels.append(x)\n    \n    for _ in range(3):\n        x = ZeroPadding2D((pad, pad), data_format=image_ordering)(x)\n        x = Conv2D(filter_size[2], (3, 3), padding='valid', data_format=image_ordering)(x)\n        x = BatchNormalization(axis=bn)(x)\n        x = Activation(\"relu\")(x)\n        x = ZeroPadding2D((pad, pad), data_format=image_ordering)(x)\n        x = Conv2D(filter_size[2], (3, 3), padding='valid', data_format=image_ordering)(x)\n        x = BatchNormalization(axis=bn)(x)\n        x = Activation(\"relu\")(x)\n        x = MaxPooling2D(pool_size=(pool_size, pool_size))(x)\n        levels.append(x)\n        \n    return img_input, levels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class UnetSegment:\n#     @staticmethod\n#     def build(height, width, channel, n_classes):\n#         input_shape = (height, width, channel)\n        \n#         if K.image_data_format() == \"channel_firsts\":\n#             input_shape = (channel, height, width)\n        \n#         model = Model()\n#         inputs = Input(shape=input_shape)\n        \n#         #Conv block 1\n#         conv_1 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", \n#                         bias_initializer=initial_bias)(inputs)\n#         conv_1 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", \n#                         bias_initializer=initial_bias, \n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_1)\n#         batch_1 = BatchNormalization()(conv_1)\n#         maxpool_1 = MaxPooling2D(pool_size=(2,2))(batch_1)\n        \n#         #Conv block 2\n#         conv_2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(maxpool_1)\n#         conv_2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_2)\n#         batch_2 = BatchNormalization()(conv_2)\n#         maxpool_2 = MaxPooling2D(pool_size=(2,2))(batch_2)\n        \n#         #Conv block 3\n#         conv_3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(maxpool_2)\n#         conv_3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_3)\n#         batch_3 = BatchNormalization()(conv_3)\n#         maxpool_3 = MaxPooling2D(pool_size=(2,2))(batch_3)\n        \n#         #Conv block 4\n#         conv_4 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(maxpool_3)\n#         conv_4 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_4)\n#         batch_4 = BatchNormalization()(conv_4)\n#         maxpool_4 = MaxPooling2D(pool_size=(2,2))(batch_4)\n        \n#         #Conv block 5\n#         conv_4_ = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(maxpool_4)\n#         drop_4_ = Dropout(0.2)(conv_4_)\n#         conv_4_ = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_4_)\n        \n#         # Decoder block 1\n#         up_1 = concatenate([UpSampling2D((2, 2))(conv_4_), conv_4], axis=-1)\n#         conv_5 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(up_1)\n#         conv_5 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_5)\n#         batch_5 = BatchNormalization()(conv_5)\n        \n#         # Decoder block 2\n#         up_2 = concatenate([UpSampling2D((2, 2))(batch_5), conv_3], axis=-1)\n#         conv_6 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(up_2)\n#         conv_6 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_6)\n#         batch_6 = BatchNormalization()(conv_6)\n        \n#         # Decoder block 3\n#         up_3 = concatenate([UpSampling2D((2, 2))(batch_6), conv_2], axis=-1)\n#         conv_7 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(up_3)\n#         conv_7 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_7)\n#         batch_7 = BatchNormalization()(conv_7)\n        \n#         # Decoder block 4\n#         up_4 = concatenate([UpSampling2D((2, 2))(batch_7), conv_1], axis=-1)\n#         conv_8 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(up_4)\n#         conv_8 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\",\n#                         bias_initializer=initial_bias,\n#                         kernel_initializer=initial_weight,\n#                         kernel_regularizer=l2(1e-4))(conv_8)\n#         batch_8 = BatchNormalization()(conv_8)\n        \n#         # Outputs model\n#         out = Conv2D(N_CLASSES, (1, 1), padding='same', activation=\"relu\")(batch_8)\n#         out = Reshape((out.shape[1]*out.shape[2], -1))(out)\n#         out = Activation(\"softmax\")(out)\n# #         print(out.shape)\n        \n#         model = Model(inputs=inputs, outputs=out)\n        \n        \n#         return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Unet:\n    @staticmethod\n    def build(encoder, n_classes=N_CLASSES, image_ordering=\"channels_last\", input_width=WIDTH, input_height=HEIGHT):\n        bn = -1\n        MERGE_AXIS = -1\n        pool_size = 2\n        pad = 1\n        \n        img_input, levels = encoder()\n        f1, f2, f3, f4, f5 = levels\n        \n        if image_ordering==\"channels_first\":\n            bn = 1\n            MERGE_AXIS = 1\n        \n        o = f4\n        o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n        o = (Conv2D(512, (3, 3), padding='valid' , activation='relu' , data_format=image_ordering))(o)\n        o = (BatchNormalization())(o)\n        o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n        o = (Conv2D(512, (3, 3), padding='valid' , activation='relu' , data_format=image_ordering))(o)\n        o = (BatchNormalization())(o)\n        \n        o = (UpSampling2D((2, 2), data_format=image_ordering))(o)\n        o = (concatenate([o, f3], axis=MERGE_AXIS))\n        o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n        o = (Conv2D(256, (3, 3), padding='valid', activation='relu' , data_format=image_ordering))(o)\n        o = (BatchNormalization())(o)\n        o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n        o = (Conv2D(256, (3, 3), padding='valid', activation='relu' , data_format=image_ordering))(o)\n        o = (BatchNormalization())(o)\n        \n        o = (UpSampling2D((2, 2), data_format=image_ordering))(o)\n        o = (concatenate([o, f2], axis=MERGE_AXIS))\n        o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n        o = (Conv2D(256, (3, 3), padding='valid' , activation='relu' , data_format=image_ordering))(o)\n        o = (BatchNormalization())(o)\n        o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n        o = (Conv2D(256, (3, 3), padding='valid' , activation='relu' , data_format=image_ordering))(o)\n        o = (BatchNormalization())(o)\n        \n        o = (UpSampling2D((2, 2), data_format=image_ordering))(o)\n        o = (concatenate([o, f1], axis=MERGE_AXIS))\n        o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n        o = (Conv2D(128, (3, 3), padding='valid', activation='relu', data_format=image_ordering))(o)\n        o = (BatchNormalization())(o)\n        o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n        o = (Conv2D(128, (3, 3), padding='valid', activation='relu', data_format=image_ordering))(o)\n        o = (BatchNormalization())(o)\n        \n        o = (UpSampling2D((2, 2), data_format=image_ordering))(o)\n#         o = (concatenate([o, f1], axis=MERGE_AXIS))\n#         o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n#         o = (Conv2D(64, (3, 3), padding='valid', activation='relu', data_format=image_ordering))(o)\n#         o = (BatchNormalization())(o)\n        \n        o = Conv2D(n_classes, (3, 3), padding='same', data_format=image_ordering)(o)\n        print(o.shape)\n        o = Reshape((o.shape[1]*o.shape[2], -1))(o)\n        out = Activation(\"softmax\")(o)\n        \n        model = Model(inputs=img_input, outputs=out)\n        \n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_segment = Unet.build(base_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_segment.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_dir = \"./weights\"\n\nif not os.path.exists(weight_dir):\n    os.mkdir(weight_dir)\n    \nfile_path = os.path.join(weight_dir, \"best_weigth.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(filepath=file_path, mode=\"min\", monitor=\"val_loss\", save_best_only=True, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_segment.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"H = unet_segment.fit_generator(data_gener.get_batch(),\n                               validation_data=(X_val, y_val),\n                               validation_steps=X_val.shape[0]//BATCH_SIZE,\n                               epochs=200, steps_per_epoch=len(data_gener.image_train_paths)//BATCH_SIZE, \n                               verbose=1, callbacks=[checkpoint], initial_epoch=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"from random import ranint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction():\n    idx = ranint(0, len(data_gener.image_test_paths))\n    img_path = data_gener.image_test_paths[idx]\n    image, seg = data_gener.load_data([img_path])\n    p = unet_segment.predict(image)[0]\n    p = p.argmax(axis=2)\n    \n    seg_img = np.zeros(())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}